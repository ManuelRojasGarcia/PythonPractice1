{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hUjrNo9ASqW"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">22.501 · Fundamentos de Programación</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grado en Ciencia de Datos Aplicada\n",
    "    </p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yk70eqzASqb"
   },
   "source": [
    "Fundamentos de Programación\n",
    "============================\n",
    "\n",
    "PEC 6: Preprocesamiento de datos en Python\n",
    "--------------------------------------\n",
    "\n",
    "En este Notebook se encontraréis el conjunto de actividades evaluables como PEC de la asignatura. Veréis que cada una de ellas tiene asociada una puntuación, que indica el peso que tiene la actividad sobre la nota final de la PEC. Adicionalmente, hay un ejercicio opcional, que no tiene puntuación dentro de la PEC, pero que se valora al final del semestre de cara a conceder las matrículas de honor y redondear las notas finales. Podréis sacar la máxima nota de la PEC sin necesidad de hacer este ejercicio. El objetivo de este ejercicio es que sirva como pequeño reto para los estudiantes que quieran profundizar en el contenido de la asignatura.\n",
    "\n",
    "Veréis que todas las actividades de la PEC tienen una etiqueta, que indica los recursos necesarios para llevarla a cabo. Hay tres posibles etiquetas:\n",
    "\n",
    "* <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span> **Sólo materiales**: las herramientas necesarias para realizar la actividad se pueden encontrar en los materiales de la asignatura.\n",
    "\n",
    "* <span style = \"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span> **Consulta externa guiada**: la actividad puede requerir hacer uso de herramientas que no se encuentran en los materiales de la asignatura, pero el enunciado contiene indicaciones de dónde o cómo encontrar la información adicional necesaria para resolver la actividad.\n",
    "\n",
    "* <span style = \"font-family: Courier New; background-color: #f2ae72; color: #000000; padding: 3px;\">EI</span> **Consulta externa independiente**: la actividad puede requerir hacer uso de herramientas que no se encuentran en los materiales de la asignatura, y el enunciado puede no incluir la descripción de dónde o cómo encontrar esta información adicional. Será necesario que el estudiante busque esta información utilizando los recursos que se han explicado en la asignatura.\n",
    "\n",
    "Es importante notar que estas etiquetas no indican el nivel de dificultad del ejercicio, sino únicamente la necesidad de consulta de documentación externa para su resolución. Además, recordad que las **etiquetas son informativas**, pero podréis consultar referencias externas en cualquier momento (aunque no se indique explícitamente) o puede ser que podáis hacer una actividad sin consultar ningún tipo de documentación. Por ejemplo, para resolver una actividad que sólo requiera los materiales de la asignatura, puedéis consultar referencias externas si queréis, ya sea tanto para ayudaros en la resolución como para ampliar el conocimiento!\n",
    "\n",
    "En cuanto a la consulta de documentación externa en la resolución de los ejercicios, recordad **citar siempre la bibliografía utilizada** para resolver cada actividad.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAEPsSOeASqc"
   },
   "source": [
    "Ejercicios para la PEC\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nzTRY11ASqd"
   },
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYJmkoZjASqd"
   },
   "source": [
    "El dataset 'Customers.csv' es un conjunto de datos que recoge información de los clientes ideales en una tienda imaginaria. El conjunto original se puede encontrar en el repositorio de datos [kaggle](https://www.kaggle.com/datasets/datascientistanna/customers-dataset?resource=download), pero el conjunto que utilizaremos tiene alguna modificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mExFVVZCASqe"
   },
   "source": [
    "(a) Importa el archivo `Customers.csv` que encontrarás en la carpeta 'data'. Muestra el tipo de variable de cada columna y su nombre, el número total de filas y columnas del dataframe y las primeras 20 filas. **(0.5 puntos)**  <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 2px; \">NM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1vMit9sASqe"
   },
   "outputs": [],
   "source": [
    "#Para obtener dtypes - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html\n",
    "#Importamos la libreria Pandas y asignamos la variable Data con el dataframe\n",
    "#Utilizamos dtypes para tipo de dato, len tamaño  y len column para columnas.\n",
    "#Finalizamos con head de 20 como indica el ejercicio.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"Customers.csv\")\n",
    "\n",
    "print(\"El tiempo de dato es:\\n\")\n",
    "print(data.dtypes)\n",
    "print(\"El número total de filas del dataframe es de:\", len(data), \"filas\\n\")\n",
    "print(\"La dimensión de columnas del dataframe es de:\", len(data.columns), \"columnas\\n\")\n",
    "print(\"A continuación mostramos las primeras 20 filas y sus respectivas columnas:\\n\")\n",
    "data.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhlTnLGPASqg"
   },
   "source": [
    "b) Hay una variable que tendría que ser de tipo 'object' pero es una variable numérica. ¿Cuál es y porque? Transfórmala para que sea de tipo 'object'. **(0.5 puntos)** <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span>\n",
    "\n",
    "**Nota** Consultad el repositorio de datos [kaggle](https://www.kaggle.com/datasets/datascientistanna/customers-dataset?resource=download) para obtener más información de cada una de las variables del dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6ME6nDPASqg"
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/59801134/the-data-type-or-dtype-of-each-column-is-properly-set-well-i-understand-the-q\n",
    "#La variable que puede ser tipo object es CustomerID ya que no vamos a realizar ninguna operación con ella y corresponden a clientes únicos.\n",
    "#Cambiamos con astype a object e imprimimos de nuevo dtypes para compobar que CustomerID ha pasado de int64 a object\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"Customers.csv\")\n",
    "\n",
    "data[\"CustomerID\"] = data[\"CustomerID\"].astype(\"object\")\n",
    "\n",
    "print(\"El tiempo de dato es\")\n",
    "print(data.dtypes)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJtZv_10ASqh"
   },
   "source": [
    "c) Eliminar los valores anómalos es un punto clave para el procesamiento de los datos para obtener un dataset de mayor calidad. Observad las variables numéricas y sustituid por `NaNs` los valores anómalos que podáis identificar. Razonad porque los consideráis anómalos. Comprobad que las variables numéricas ya no contienen estos valores anómalos después de la modificación. **(1 punto)**  <span style=\"font-family: Courier New; background-color: #f2ae72; color: #000000; padding: 3px; \">EI</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmRMA1tOASqi"
   },
   "outputs": [],
   "source": [
    "#http://exponentis.es/como-encontrar-valores-nan-en-un-dataframe-python-pandas-y-modificarlos\n",
    "#https://www.geeksforgeeks.org/detect-and-remove-the-outliers-using-python/\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "#Se usan las web superiores para realizar el ejercicio, se comenta cada apartado.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Customers.csv\")\n",
    "\n",
    "#Antes de comenzar calculamos cuantos NaN tenemos en el dataframe\n",
    "NaNinicial = data.isna().sum()\n",
    "\n",
    "print(\"El número de NaN inicialmentes es de:\\n\", NaNinicial)\n",
    "\n",
    "#Se imprime las filas con datos anomalos\n",
    "\n",
    "print(\"Filas con ingresos anuales iguales a 0\\n\", np.where((data['AnnualIncome']== 0)))\n",
    "print(\"Filas con edad = 0\", np.where((data['Age'] == 0 )))\n",
    "print(\"Filas con edad superiores a 99 años\\n\", np.where((data['Age'] >= 99 )))\n",
    "print(\"Filas con años trabajados superior a 50 años\\n\", np.where((data['WorkExperience'] >= 50 )))\n",
    "print(\"Filas con tamaño de familia superior a 9\\n\", np.where((data['FamilySize'] >= 9 )))\n",
    "\n",
    "# Imprimimos un ejemplo donde claramente se detecta una fila con un ID con edad de 400 años, siendo claramente incorrecto\n",
    "fila1 = data.loc[122]  \n",
    "print(\"Se imprimer una fila de ejemplo con una edad de 400años:\\n\", fila1)\n",
    "\n",
    "#Limpiamos los datos y rellenamos con NaN\n",
    "AnnualIncomelimpio = data['AnnualIncome'] == 0\n",
    "data.loc[AnnualIncomelimpio, 'AnnualIncome'] = np.NaN\n",
    "Edadlimpio = data['Age'] == 0\n",
    "data.loc[Edadlimpio, 'Age'] = np.NaN\n",
    "Edadlimpio2 = data['Age'] >99\n",
    "data.loc[Edadlimpio2, 'Age'] = np.NaN\n",
    "worklimpio = data['WorkExperience'] >=50\n",
    "data.loc[worklimpio, 'WorkExperience'] = np.NaN\n",
    "familylimpio = data['FamilySize'] >=9\n",
    "data.loc[familylimpio, 'FamilySize'] = np.NaN\n",
    "\n",
    "#Comprobamos que es no existen esas lineas\n",
    "\n",
    "print(\"Comprobamos que ya no existen esas lineas\", np.where((data['AnnualIncome']== 0)))\n",
    "print(\"Comprobamos que ya no existen esas lineas\", np.where((data['Age'] == 0 )))\n",
    "print(\"Comprobamos que ya no existen esas lineas\", np.where((data['Age'] >= 100 )))\n",
    "print(\"Comprobamos que ya no existen esas lineas\", np.where((data['WorkExperience'] >= 50 )))\n",
    "print(\"Comprobamos que ya no existen esas lineas\", np.where((data['FamilySize'] >= 9 )))\n",
    "\n",
    "#Creamos una variable con los datos NaN incluidos.\n",
    "\n",
    "NaNFinal = data.isna().sum()\n",
    "\n",
    "print(\"El número de NaN despues del procesamiento de datos es de:\\n\", NaNFinal)\n",
    "\n",
    "#Creamos una variable para incluir todas las filas que contenga NaN e imprimimos\n",
    "\n",
    "DataconNaN = data[data.isnull().any(1)]\n",
    "print(DataconNaN)\n",
    "\n",
    "#Creamos otra variable sin incluir los NaN\n",
    "\n",
    "DatasinNaN = data.dropna(how='any')\n",
    "DatasinNaN.head(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLPy3I6CASqi"
   },
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrLRMxmOASqi"
   },
   "source": [
    "a) Muestra los diferentes valores de la columna \"Profession\" y el número de clientes para cada profesión. ¿Qué profesión proporciona más clientes? Muestra el resultado mediante un `pie chart` **(1 punto)** <span style=\"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span>\n",
    "\n",
    "**Nota** Tenéis que añadir la frecuencia de cada profesión dentro del `pie chart` con dos decimales. Podéis consultar la documentación de [matplotlib](https://matplotlib.org/stable/gallery/pie_and_polar_charts/pie_features.html) para realizar este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdYp8Q0LASqj"
   },
   "outputs": [],
   "source": [
    "#https://matplotlib.org/stable/gallery/pie_and_polar_charts/pie_features.html\n",
    "#https://interactivechaos.com/es/python/scenario/calculo-del-numero-de-apariciones-de-cada-elemento-en-una-serie-pandas\n",
    "#https://numpy.org/doc/stable/reference/generated/numpy.unique.html\n",
    "#https://note.nkmk.me/en/python-pandas-len-shape-size/\n",
    "#Se utilizan las webs superiores para poder realizar el ejercicio.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Customers.csv\")\n",
    "\n",
    "profesionesUnicas = data['Profession'].unique()\n",
    "\n",
    "print(profesionesUnicas)\n",
    "\n",
    "profesiones = data['Profession'].value_counts()\n",
    "print(profesiones)\n",
    "artistas = profesiones.max()\n",
    "\n",
    "print(\"La profesión que más se repite es:\", profesionesUnicas[4], \"con\", artistas)\n",
    "\n",
    "\n",
    "labels = 'Healthcare', 'Engineer', 'Lawyer', 'Entertainment', 'Artist', 'Executive', 'Doctor', 'Homemaker','Marketing', 'nan' \n",
    "\n",
    "sizes = [data[data['Profession'] == 'Healthcare'].shape[0],\n",
    "    data[data['Profession'] == 'Engineer'].shape[0],\n",
    "    data[data['Profession'] == 'Lawyer'].shape[0],\n",
    "    data[data['Profession'] == 'Entertainment'].shape[0],\n",
    "    data[data['Profession'] == 'Artist'].shape[0],\n",
    "    data[data['Profession'] == 'Executive'].shape[0],\n",
    "    data[data['Profession'] == 'Doctor'].shape[0],\n",
    "    data[data['Profession'] == 'Homemaker'].shape[0],\n",
    "    data[data['Profession'] == 'Marketing'].shape[0],\n",
    "    data['Profession'].isnull().sum()\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels, autopct='%1.2f%%')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwDfDc0VASqj"
   },
   "source": [
    "b) Para aumentar la rentabilidad del negocio, se quiere realizar una campaña publicitaria para aumentar el consumo medio por profesión. Por eso, se quiere orientar la campaña publicitaria al sector con menos consumo medio. ¿Cuál tendría que ser este sector? Ordena el consumo mediano por profesión de mayor a menor. **(1 punto)** <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYeKnX5uASqk"
   },
   "outputs": [],
   "source": [
    "#https://datatofish.com/sort-pandas-dataframe/\n",
    "#Se utiliza la referencia superior para obtener el ejercicio.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Customers.csv\")\n",
    "\n",
    "profesionesUnicas = data['Profession'].unique()\n",
    "\n",
    "columnas_seleccionadas = data[['Profession', 'SpendingScore']]\n",
    "\n",
    "Mediaprofesion = columnas_seleccionadas.groupby('Profession')['SpendingScore'].mean()\n",
    "\n",
    "Mediaprofesionordenada = Mediaprofesion.sort_values(ascending=False)\n",
    "print(Mediaprofesionordenada)\n",
    "\n",
    "print(\"El consumo medio menor por profesion es:\", profesionesUnicas[7], \"con un valor de\", Mediaprofesionordenada[8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVWuQj4BASqk"
   },
   "source": [
    "### Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UU8659CASql"
   },
   "source": [
    "Queremos respresentar la variable `Age` como una variable discreta en lugar de contínua, porque nos interesa separar esta información en tres categorías: young, adult, old. Separa la variable en tres grupos de forma uniforme, considerando que el primer grupo corresponde a la categoría \"young\", el segundo corresponde a \"adult\" y finalmente, la última categoría a \"old\". Crea una nueva columna con el nombre de \"AgeCategory\" donde clasificaremos las personas como \"young\", \"adult\" y \"old\", muestra el nombre de filas para cada una de las categorías, así como la media de ingresos por categoría. ¿En qué categoría el ingreso medio es más alto? **(1 punto)** <span style=\"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span>\n",
    "\n",
    "**Nota** Para realizar este ejercicio podéis utilizar las funciones de [pandas](https://pandas.pydata.org/docs/reference/general_functions.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiwVGuz9ASql"
   },
   "outputs": [],
   "source": [
    "#https://joserzapata.github.io/courses/python-ciencia-datos/pandas/\n",
    "#https://www.delftstack.com/es/howto/python-pandas/how-to-create-dataframe-column-based-on-given-condition-in-pandas/\n",
    "#Para eliminar el type cuando imprimo  - https://www.appsloveworld.com/pandas/100/13/how-do-i-remove-name-and-dtype-from-pandas-output\n",
    "#Creamos la división con pd.cut, pero dejo un código debajo para hacerlo con diferencias de hasta 18 años, de 18 a 65 y mayor de 65\n",
    "#Los datos no son iguales.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Customers.csv\")\n",
    "\n",
    "edad = data['Age'].unique()\n",
    "\n",
    "data['AgeCategory'] = pd.qcut(data['Age'], q=3, labels=['young', 'adult', 'old'])\n",
    "\n",
    "youngtotales = []\n",
    "for category in data['AgeCategory']:\n",
    "    if category == 'young':\n",
    "        youngtotales.append(category)\n",
    "adulttotales = []\n",
    "for category in data['AgeCategory']:\n",
    "    if category == 'adult':\n",
    "        adulttotales.append(category)\n",
    "oldtotales = []\n",
    "for category in data['AgeCategory']:\n",
    "    if category == 'old':\n",
    "        oldtotales.append(category)\n",
    "\n",
    "sumatorioyoung = pd.Series(youngtotales).value_counts()\n",
    "sumatorioadult = pd.Series(adulttotales).value_counts()\n",
    "sumatorioold = pd.Series(oldtotales).value_counts()\n",
    "young = sumatorioyoung.tolist()\n",
    "adult = sumatorioadult.tolist()\n",
    "old = sumatorioold.tolist()\n",
    "print(f\"Total de young: {young}\")\n",
    "print(f\"Total de aldult: {adult}\")\n",
    "print(f\"Total de old: {old}\")\n",
    "\n",
    "\n",
    "columnas_seleccionadas = data[['AgeCategory', 'AnnualIncome']]\n",
    "\n",
    "Mediaprofesion = columnas_seleccionadas.groupby('AgeCategory')['AnnualIncome'].mean()\n",
    "Mediaprofesionredondeada = round(Mediaprofesion, 2)\n",
    "print(\"La media de ingresos anuales según la categoria de edad es de:\\n\", Mediaprofesionredondeada)\n",
    "print(\"El ingreso medio más alto es:\", Mediaprofesionredondeada.idxmax(), \"con\", Mediaprofesionredondeada.max())\n",
    "\n",
    "\n",
    "#Otro código con una separación más razonable por edad.\n",
    "\n",
    "#data['AgeCategory'] = [\"Junior\" if age <= 18 else \"Adult\" if age <= 65 else \"Old\" for age in data['Age']\n",
    "#Young = data['Age'] <= 18 \n",
    "#Adult = (data['Age'] >= 18) & (data['Age'] <= 65)\n",
    "#Old = data['Age'] >= 65 \n",
    "\n",
    "#Youngtotales = Young.sum()\n",
    "#Adulttotales = Adult.sum()\n",
    "#Oldtotales = Old.sum()\n",
    "\n",
    "#print(f\"El número total de jóvenes: {Youngtotales}\")\n",
    "#print(f\"El número total de adultos: {Adulttotales}\")\n",
    "#print(f\"El número total de ancianos: {Oldtotales}\")\n",
    "\n",
    "#columnas_seleccionadas = data[['AgeCategory', 'AnnualIncome']]\n",
    "\n",
    "#Mediaprofesion = columnas_seleccionadas.groupby('AgeCategory')['AnnualIncome'].mean()\n",
    "#Mediaprofesionredondeada = round(Mediaprofesion, 2)\n",
    "#print(\"La media de ingresos anuales según la categoria de edad es de:\\n\", Mediaprofesionredondeada)\n",
    "#print(\"El ingreso medio más alto es:\", Mediaprofesionredondeada.idxmax(), \"con\", Mediaprofesionredondeada.max())\n",
    "\n",
    "#data.head(n=25)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riS3Zt_LASql"
   },
   "source": [
    "### Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91zLrUbfASqm"
   },
   "source": [
    "El conjunto de datos 'github.csv' contiene información de algunos repositorios de la paltaforma de desarrollo colaborativo GitHub. El que utilizaremos en esta parte tiene algunas modificaciones comparado con el original que se puede encontrar en [kaggle](https://www.kaggle.com/datasets/nikhil25803/github-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BQhZi2nASqm"
   },
   "source": [
    "a) Importa el fichero 'github.csv' que encontrarás en la carpeta 'data'. Muestra el nombre de las columnas y el número total de filas utilizando los atributos de los *dataframes*. Selecciona una muestra del 35% de los datos de forma aleatória. Seguidamente, muestra por pantalla las últimas 10 filas de esta muestra. **(0.5 puntos)** <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7K8u9LuvASqm"
   },
   "outputs": [],
   "source": [
    "#https://www.analyticslane.com/2020/12/07/pandas-obtener-el-nombre-de-las-columnas-y-filas-en-pandas/\n",
    "#Para la muestra se usa data.sample de los apuntes con 0.35 como indica el ejercicio\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Github.csv\")\n",
    "\n",
    "columns = data.columns.values\n",
    "\n",
    "print(\"El tiempo de dato es:\\n\")\n",
    "print(data.dtypes)\n",
    "print(\"El número total de filas del dataframe es de:\", len(data), \"filas\\n\")\n",
    "print(\"La dimensión de columnas del dataframe es de:\", len(data.columns), \"columnas\\n\")\n",
    "print(\"El nombre las columnas son:\", columns)\n",
    "\n",
    "sampled_data = data.sample(frac=0.35)\n",
    "sampled_data.tail(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9SenOBSASqm"
   },
   "source": [
    "b) Para un correcto tratamiento de los datos queremos trabajar con filas que no tengan valores nulos en las columnas. Borra las que tengan alguno y, después, vuelve a mostrar por pantalla la cantidad de filas restantes. **(1 punto)** <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGRAt8cPASqn"
   },
   "outputs": [],
   "source": [
    "#https://www.delftstack.com/es/howto/python-pandas/pandas-drop-rows-with-nan/\n",
    "\n",
    "#Reutilizo código de los primeros ejercicios.\n",
    "#Inicialmente hay 1052 filas, se le restan las 145 eliminadas y dan un total de 907.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Github.csv\")\n",
    "\n",
    "NaNInicial = data.isna().sum()\n",
    "\n",
    "print(\"El número de NaN despues del procesamiento de datos es de:\", NaNInicial)\n",
    "\n",
    "\n",
    "DatasinNaN = data.dropna(how='any')\n",
    "DatasinNaN.head(n=50)\n",
    "\n",
    "columns = DatasinNaN.columns.values\n",
    "\n",
    "\n",
    "print(\"El número total de filas del dataframe es de:\", len(DatasinNaN), \"filas\\n\")\n",
    "print(\"La dimensión de columnas del dataframe es de:\", len(DatasinNaN.columns), \"columnas\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cth9utY5ASqn"
   },
   "source": [
    "c) Queremos ver cuáles son los 5 usuarios (y solo estos) que tienen más repositorios al conjunto de datos, ordenados de **menos a más**. Para ello, se pide crear dos columnas nuevas a partir de 'repositories': user y repository_name. **(1.5 puntos)** <span style=\"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span>\n",
    "\n",
    "**NOTA:** La columna 'repositories' tiene el siguiente formato: usuario/nombre_repositorio. Puedes consultar [el apartado de *series*](https://pandas.pydata.org/docs/reference/series.html) de la documentación de Pandas para elegir la función más adecuada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXs1WPpnASqn"
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/54015770/splitting-of-words-in-pandas-dataframe\n",
    "#Para separar la palabra con lambda se usa el link superior.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Github.csv\")\n",
    "\n",
    "data['user'] = data['repositories'].apply(lambda x: x.split('/')[0])\n",
    "data['repository_name'] = data['repositories'].apply(lambda x: x.split('/')[1])\n",
    "\n",
    "contadorusuarios = data['user'].value_counts()\n",
    "contadorusuariosordenada = contadorusuarios.sort_values(ascending=False)\n",
    "Primeros = contadorusuariosordenada[:5]\n",
    "usuariomax = Primeros.max()\n",
    "\n",
    "print(Primeros[::-1])\n",
    "print(\"El usuario con más repositorios es iamshaunjp con\", usuariomax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBH_ghLiASqn"
   },
   "source": [
    "### Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuu-qGAOASqn"
   },
   "source": [
    "Nos han pedido filtrar la información del conjunto de datos para realizar estadísticas sobre los repositorios de GitHub. A continuación se encuentran los puntos solicitados: **(2 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsNZuGPLASqo"
   },
   "source": [
    "1) Lista los repositorios que tengan más de 900 estrellas o más de 650 forks. **(0.25 puntos)** <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span>\n",
    "\n",
    "2) Indica cuantos y qué repositorios no han tenido contribuidores ni estrellas. **(0.25 puntos)** <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span>\n",
    "\n",
    "3) ¿Cuál es el lenguaje de programación más utilizado por el usuario openfoodfacts? ¿Cuántas veces lo ha utilizado? **(0.5 puntos)** <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span>\n",
    "\n",
    "4) ¿Qué repositorio ha tenido más interacciones en total? Las columnas que se consideran interacciones son: stars_count, forks_count, issues_count i pull_requests. **(0.5 puntos)** <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">NM</span>\n",
    "\n",
    "5) Muestra los tres lenguajes con más contribuidores. **(0.5 puntos)** <span style=\"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span>\n",
    "\n",
    "**NOTA:** Para este último punto utiliza la función *nlargest()* que puedes consultar [aquí](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZuEF3qqASqo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Github.csv\")\n",
    "\n",
    "data['user'] = data['repositories'].apply(lambda x: x.split('/')[0])\n",
    "\n",
    "columnasseleccionada1 = data['stars_count']\n",
    "columnasseleccionada2 = data['forks_count']\n",
    "\n",
    "print(\"El siguiente listado tiene más de 650 forks o más de 900 estrellas:\")\n",
    "masde900 =[]\n",
    "for i, user in zip(columnasseleccionada1, data['user']):\n",
    "    if i >= 900:\n",
    "        masde900.append((user, i))\n",
    "masde650 =[]\n",
    "for i, user in zip(columnasseleccionada2, data['user']):\n",
    "    if i >= 650:\n",
    "        masde650.append((user, i))\n",
    "\n",
    "for i, n in masde900 and masde650:\n",
    "    print(i, n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOylbloqASqo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Github.csv\")\n",
    "data['user'] = data['repositories'].apply(lambda x: x.split('/')[0])\n",
    "\n",
    "\n",
    "columnasseleccionada1 = data['stars_count']\n",
    "columnasseleccionada2 = data['contributors']\n",
    "usuarios = data['user']\n",
    "\n",
    "print(\"El siguiente listado tiene 0 contribuciones y 0 estrellas:\")\n",
    "\n",
    "total = []\n",
    "\n",
    "for i, j, usuario in zip(columnasseleccionada1, columnasseleccionada2, usuarios):\n",
    "    if i == 0 and j == 0:\n",
    "        total.append((usuario, i))\n",
    "\n",
    "for usuario in total:\n",
    "    print(usuario)\n",
    "\n",
    "print(\"El número total de repositorios sin estrellas y contribuciones es de:\", len(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1557,
     "status": "ok",
     "timestamp": 1685401028237,
     "user": {
      "displayName": "Manuel Rojas Garcia",
      "userId": "01932368244221494376"
     },
     "user_tz": -120
    },
    "id": "VR384fA-ASqo",
    "outputId": "d4e46d14-8869-4a8b-f1e1-5ec6a43ac6e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
      "La cantidad de NaN en lenguaje de openfoodfacts es de: 6\n",
      "El siguiente listado es el lenguaje utilizado por openfoodfacts\n",
      "C++: 1\n",
      "Python: 2\n",
      "Ruby: 1\n",
      "Java: 2\n",
      "CSS: 3\n",
      "Dart: 2\n",
      "Jinja: 1\n",
      "HTML: 1\n",
      "Objective-C: 1\n",
      "El lenguaje más usado de openfoodfacts es CSS con 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Github.csv\")\n",
    "data['user'] = data['repositories'].apply(lambda x: x.split('/')[0])\n",
    "columnasseleccionada1 = data['language']\n",
    "\n",
    "\n",
    "open =[]\n",
    "\n",
    "for i in data['user']:\n",
    "  if i == 'openfoodfacts':\n",
    "    open.append(i)\n",
    "\n",
    "openylenguaje =[]\n",
    "for i, user in zip(columnasseleccionada1, open):\n",
    "    openylenguaje.append((user,i))\n",
    "\n",
    "\n",
    "openylenguajecontador = {'nan': 0,'C++': 0,'Python': 0,'Ruby': 0,'Java': 0,'CSS': 0,'Dart': 0,'Jinja': 0,'HTML': 0,'Objective-C': 0}\n",
    "\n",
    "for user, language in openylenguaje:\n",
    "    if language in openylenguajecontador:\n",
    "        openylenguajecontador[language] += 1\n",
    "    else:\n",
    "        openylenguajecontador['nan'] += 1\n",
    "\n",
    "cantidadNaN = openylenguajecontador['nan']\n",
    "cantidadcmasmas = openylenguajecontador['C++']\n",
    "cantidadpython = openylenguajecontador['Python']\n",
    "cantidadruby = openylenguajecontador['Ruby']\n",
    "cantidadjava = openylenguajecontador['Java']\n",
    "cantidadcss = openylenguajecontador['CSS']\n",
    "cantidaddart = openylenguajecontador['Dart']\n",
    "cantidadjinja = openylenguajecontador['Jinja']\n",
    "cantidadhtml = openylenguajecontador['HTML']\n",
    "cantidadobjectivec = openylenguajecontador['Objective-C']\n",
    "print(\"La cantidad de NaN en lenguaje de openfoodfacts es de:\", cantidadNaN)\n",
    "print(\"El siguiente listado es el lenguaje utilizado por openfoodfacts\")\n",
    "\n",
    "print(\"C++:\", cantidadcmasmas)\n",
    "print(\"Python:\", cantidadpython)\n",
    "print(\"Ruby:\", cantidadruby)\n",
    "print(\"Java:\", cantidadjava)\n",
    "print(\"CSS:\", cantidadcss)\n",
    "print(\"Dart:\", cantidaddart)\n",
    "print(\"Jinja:\", cantidadjinja)\n",
    "print(\"HTML:\", cantidadhtml)\n",
    "print(\"Objective-C:\", cantidadobjectivec)\n",
    "\n",
    "\n",
    "print(\"El lenguaje más usado de openfoodfacts es CSS con\", cantidadcss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1945,
     "status": "ok",
     "timestamp": 1685401169402,
     "user": {
      "displayName": "Manuel Rojas Garcia",
      "userId": "01932368244221494376"
     },
     "user_tz": -120
    },
    "id": "eyPoZmCxASqo",
    "outputId": "45d9392e-68a5-4596-ed32-4823f030c2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
      "La suma de cada repositorio es: [928, 963, 340, 320, 813, 172, 328, 310, 310, 1403, 121, 125, 555, 91, 85, 117, 647, 434, 1041, 236, 454, 1060, 57, 899, 899, 104, 460, 1597, 363, 73, 281, 500, 242, 517, 185, 434, 269, 243, 334, 288, 254, 216, 265, 373, 68, 173, 179, 31, 314, 87, 1243, 608, 944, 37, 1172, 293, 926, 237, 997, 25, 252, 331, 1062, 860, 167, 33, 1020, 243, 231, 108, 108, 57, 73, 314, 589, 184, 22, 39, 164, 53, 215, 21, 112, 363, 1262, 291, 363, 291, 291, 324, 445, 693, 885, 57, 707, 399, 61, 30, 465, 244, 270, 16, 458, 311, 177, 44, 353, 469, 20, 460, 516, 94, 760, 51, 418, 42, 23, 530, 95, 95, 322, 14, 103, 1323, 82, 102, 14, 84, 440, 125, 1216, 421, 25, 38, 443, 29, 25, 52, 19, 123, 96, 93, 200, 85, 89, 21, 289, 43, 21, 403, 18, 733, 1003, 255, 31, 31, 112, 34, 1013, 595, 24, 11, 1013, 22, 19, 118, 45, 52, 11, 60, 29, 30, 261, 27, 236, 257, 10, 31, 338, 493, 353, 26, 700, 20, 1020, 768, 359, 245, 11, 534, 12, 571, 52, 114, 937, 861, 700, 359, 187, 20, 229, 534, 654, 30, 1105, 591, 15, 116, 8, 98, 577, 8, 89, 45, 67, 786, 65, 14, 17, 8, 9, 38, 8, 236, 483, 8, 140, 125, 15, 40, 896, 115, 14, 438, 8, 10, 393, 18, 9, 145, 392, 86, 602, 40, 958, 324, 11, 21, 77, 232, 11, 177, 18, 35, 967, 141, 35, 6, 1221, 7, 409, 42, 23, 7, 158, 46, 46, 888, 766, 38, 359, 672, 359, 79, 8, 86, 666, 7, 10, 24, 90, 27, 13, 5, 808, 618, 119, 8, 698, 15, 12, 18, 189, 25, 86, 18, 5, 17, 29, 62, 698, 88, 35, 27, 103, 141, 51, 15, 12, 62, 62, 189, 5, 9, 65, 43, 332, 191, 100, 78, 555, 340, 34, 28, 78, 342, 68, 603, 94, 4, 37, 21, 8, 448, 194, 15, 194, 32, 524, 7, 227, 35, 174, 14, 667, 754, 12, 20, 19, 26, 9, 27, 58, 4, 11, 262, 18, 7, 52, 5, 26, 7, 34, 686, 4, 760, 407, 9, 195, 76, 13, 609, 214, 39, 258, 109, 95, 15, 20, 390, 10, 4, 656, 553, 95, 42, 4, 302, 584, 5, 34, 25, 147, 95, 240, 3, 607, 553, 6, 95, 17, 36, 145, 954, 9, 17, 4, 9, 279, 629, 158, 14, 193, 13, 70, 3, 7, 234, 58, 38, 19, 20, 13, 142, 125, 245, 5, 14, 418, 6, 36, 43, 36, 38, 25, 873, 89, 99, 177, 85, 28, 196, 229, 342, 584, 4, 7, 17, 27, 244, 3, 302, 94, 51, 69, 10, 43, 7, 19, 123, 175, 63, 71, 4, 261, 575, 548, 387, 10, 125, 560, 3, 278, 48, 20, 5, 30, 947, 131, 6, 3, 15, 73, 2, 208, 442, 28, 6, 17, 3, 9, 25, 2, 43, 79, 79, 11, 10, 11, 64, 178, 246, 437, 4, 183, 129, 31, 4, 5, 489, 75, 23, 12, 18, 551, 2, 11, 548, 103, 2, 3, 207, 25, 4, 15, 38, 5, 29, 277, 954, 46, 15, 108, 6, 11, 281, 63, 10, 27, 2, 4, 235, 97, 963, 38, 2, 4, 319, 22, 315, 213, 3, 123, 168, 2, 205, 93, 5, 44, 192, 2, 29, 2, 2, 3, 5, 11, 751, 356, 30, 115, 6, 82, 10, 11, 4, 437, 442, 89, 131, 19, 19, 297, 29, 3, 4, 10, 19, 18, 107, 234, 63, 2, 120, 8, 322, 138, 6, 110, 315, 7, 12, 14, 30, 115, 244, 234, 6, 103, 50, 297, 42, 120, 82, 2, 222, 901, 168, 3, 2, 17, 25, 198, 7, 6, 140, 4, 47, 649, 2, 48, 47, 103, 113, 2, 8, 5, 3, 18, 32, 1, 11, 53, 1, 132, 5, 9, 1, 1, 13, 15, 1, 139, 2, 35, 15, 585, 63, 56, 6, 5, 9, 5, 4, 8, 6, 7, 16, 5, 8, 19, 50, 65, 7, 8, 2, 28, 14, 72, 11, 1, 2, 6, 1, 266, 31, 6, 1, 35, 158, 123, 82, 27, 54, 4, 4, 21, 6, 7, 936, 1, 1, 115, 2, 56, 18, 18, 8, 450, 1, 1, 378, 4, 9, 51, 2, 6, 34, 1, 47, 17, 1, 61, 2, 11, 201, 4, 4, 1, 23, 2, 21, 3, 8, 38, 1, 96, 92, 424, 214, 19, 2, 3, 13, 17, 179, 115, 4, 138, 36, 17, 1, 1, 1, 8, 1, 1, 224, 7, 48, 85, 3, 8, 402, 135, 140, 400, 3, 1, 17, 19, 17, 269, 12, 6, 51, 22, 11, 69, 8, 28, 56, 144, 66, 4, 13, 9, 1, 66, 2, 25, 2, 2, 2, 21, 6, 20, 20, 471, 100, 1, 1, 1, 1, 30, 3, 73, 13, 114, 18, 52, 35, 12, 6, 1, 25, 3, 1, 5, 37, 143, 117, 4, 21, 36, 22, 4, 2, 3, 3, 9, 1, 42, 28, 17, 173, 4, 2, 611, 2, 87, 159, 58, 36, 20, 8, 139, 8, 2, 13, 21, 2, 23, 4, 1, 8, 2, 13, 21, 1, 22, 2, 93, 20, 86, 8, 872, 8, 9, 1, 22, 1, 2, 20, 8, 3, 2, 9, 1, 1, 58, 3, 1, 8, 141, 112, 32, 36, 159, 2, 93, 20, 86, 8, 872, 8, 9, 4, 87, 23, 2, 4, 2, 611, 2, 24, 46, 4, 1, 378, 119, 4, 16, 10, 1, 46, 20, 140, 4, 9, 9, 2, 16, 8, 164, 642, 10, 5, 3, 31, 71, 1, 1, 17, 3, 62, 6, 285, 36, 4, 136, 458, 6, 2, 8, 7, 23, 25, 18, 82, 121, 1, 51, 1, 3, 1, 1, 6, 18, 20, 16, 2, 2, 68, 1, 2, 1, 1, 1, 1, 6, 1, 13, 18, 31, 2, 173, 3, 1, 4, 2, 2, 14, 32, 17, 18, 27, 17, 19, 16, 6, 9, 8, 3, 55, 23, 2, 1, 78, 23, 64, 8, 9, 22, 11, 929, 37, 1, 45, 2, 1, 75, 50, 674, 59, 1, 129, 7, 36, 60, 1, 72, 8, 183, 1, 317, 7, 95, 8, 2, 9, 17, 6, 1, 14, 66, 23, 1, 1, 4, 3, 74, 3, 39, 167, 62, 17, 4, 1, 7, 17, 8]\n",
      "El repositorio máximo tiene 1597 reposiciones y esta en la posición 27\n",
      "El repositorio que ha tenido más interacciones en total es:\n",
      " repositories     EddieHubCommunity/awesome-github-profiles\n",
      "stars_count                                            925\n",
      "forks_count                                            612\n",
      "issues_count                                            51\n",
      "pull_requests                                            9\n",
      "contributors                                           434\n",
      "language                                              HTML\n",
      "Name: 27, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Para recorrer el dataframe con interows - https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "#Para obtener la posición dentro del dataframe https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Github.csv\")\n",
    "\n",
    "dataseleccionados = data[['stars_count', 'forks_count', 'issues_count', 'pull_requests']]\n",
    "\n",
    "sumarepositorio = []\n",
    "\n",
    "for i, filas in dataseleccionados.iterrows():\n",
    "    suma = filas.sum(axis=0)\n",
    "    sumarepositorio.append(suma)\n",
    "\n",
    "repositoriomax = max(sumarepositorio)\n",
    "posicion1597 = sumarepositorio.index(1597)\n",
    "posicion27 = data.iloc[27]\n",
    "\n",
    "print(\"La suma de cada repositorio es:\", sumarepositorio)\n",
    "print(\"El repositorio máximo tiene\", repositoriomax, \"reposiciones\", \"y esta en la posición\", posicion1597)\n",
    "print(\"El repositorio que ha tenido más interacciones en total es:\\n\", posicion27)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1972,
     "status": "ok",
     "timestamp": 1685401174748,
     "user": {
      "displayName": "Manuel Rojas Garcia",
      "userId": "01932368244221494376"
     },
     "user_tz": -120
    },
    "id": "EPH9wZFWASqp",
    "outputId": "598b399a-33b5-4067-d223-65fec35295fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
      "Los tres lenguajes con más contribuciones son:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "JavaScript    1825\n",
       "HTML          1568\n",
       "Python        1271\n",
       "Name: contributors, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   \n",
    "%cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_6/data\n",
    "\n",
    "data = pd.read_csv(\"Github.csv\")\n",
    "dataseleccionados = data.groupby('language')['contributors'].sum()\n",
    "print(\"Los tres lenguajes con más contribuciones son:\")\n",
    "dataseleccionados.nlargest(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1iXRVaqASqp"
   },
   "source": [
    "### Ejercicio opcional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1ZnBm8_ASqp"
   },
   "source": [
    "Comenta el siguiente código y explica para qué sirve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vg5boMiwASqp"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "qt = preprocessing.QuantileTransformer(random_state=0)\n",
    "\n",
    "df[[\"AnnualIncome\", \"SpendingScore\"]] = qt.fit_transform(\n",
    "    df[[\"AnnualIncome\", \"SpendingScore\"]])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STo8INpSASqp"
   },
   "outputs": [],
   "source": [
    "# Fuentes: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html\n",
    "# http://datascience.recursos.uoc.edu/es/preprocesamiento-de-datos-con-sklearn/\n",
    "\n",
    "\n",
    "# Se importa la libreria scikit-learn que es un conjunto de rutinas escritas en Python para hacer análisis predictivo, que incluyen clasificadores, algoritmos de clusterización, etc. Está basada en NumPy, SciPy y matplotlib, de forma que es fácil reaprovechar el código que use estas librerías.\n",
    "# En este caso se utiliza Transformaciones, para transformar variables con distribuciones muy sesgadas.\n",
    "# Transforme características usando información de cuantiles. Esta transformación es útil para mitigar los efectos de los valores atípicos y mejorar la distribución de los datos\n",
    "# Este método transforma las características para seguir una distribución uniforme o normal. Por tanto, para una determinada característica, esta transformación tiende a dispersar los valores más frecuentes. También reduce el impacto de los valores atípicos (marginales): por lo tanto, se trata de un esquema de preprocesamiento robusto.\n",
    "# El código utiliza una técnica especial llamada transformación de cuantiles para mejorar la distribución de los datos y manejar los valores extremos. Los datos transformados se reemplazan en el conjunto de datos original y se muestra una vista previa para que podamos ver cómo lucen los datos transformados."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "e404b59586357c814bc0d3940e75d6763c00a48753b225b81f7716971b8e1741"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
